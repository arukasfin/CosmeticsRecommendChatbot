{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faUojVtgaTGc"
   },
   "source": [
    "# 호텔 챗봇\n",
    "\n",
    "이 노트북에서는 호텔 챗봇 문제를 다룹니다. 어떻게 하면 호텔 프론트 데스크에서 더 나은 고객 서비스를 제공할 수 있을까요? 간단한 방법 중 하나는 호텔에서 경험할 수 있는 일들에 관한 간단한 질문에 대답할 수 있는 FAQ 채팅 로봇을 갖는 것입니다. 챗봇을 갖는 것에는 많은 장점이 있습니다.\n",
    "\n",
    "1. 호텔의 매력을 높이고 정보 처리량을 늘립니다.\n",
    "2. 호텔에 대한 질문을 데이터 테이블 형식으로 수집할 수 있는 방법을 만듭니다.\n",
    "\n",
    "이 노트북에서는 두 가지 모델을 살펴볼 것입니다. 코사인 유사성 및 doc2vec 모델입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNceALtVaTGc"
   },
   "source": [
    "## 1. 챗봇에 지식 기반 추가\n",
    "\n",
    "챗봇의 대화 능력은 사용할 수 있는 데이터에 의해 정의됩니다. Ques.txt 파일과 ans.txt 파일에서 질문과 답변을 살펴보십시오. 이 챗봇은 기본적으로 질문에 대하여 질문 은행과 코사인 유사성을 확인하여 답을 찾으려고 노력할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1625201864601,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "e__0bwBTaTGd"
   },
   "outputs": [],
   "source": [
    "import nltk # 텍스트 데이터를 처리\n",
    "import numpy as np # 말뭉치를 배열로 표현\n",
    "import random \n",
    "import operator\n",
    "import string # 표준 파이썬 문자열을 처리\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity # 이를 나중에 사용하여 두 개의 문장이 얼마나 비슷한지를 결정합니다.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Experience 2에서 단어 가방을 만드는 함수를 만들었던 것을 기억하십니까? 이 함수는 같은 일을 합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 데이터 처리\n",
    "#### 1.2.1 파일 읽기 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1625201865138,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "R08PteSZaTGd",
    "outputId": "f9bf11e9-f1b9-45c7-91b2-70fdc692dc29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw_data_ques: 240\n",
      "Length of raw_data_ans: 831\n"
     ]
    }
   ],
   "source": [
    "# 1.[Dataset] Module27 (ans).txt 파일을 읽어 raw_data_ans 에 저장한다.\n",
    "# 2.[Dataset] Module27 (ques).txt 파일을 읽어 raw_data_ques 에 저장한다. \n",
    "\n",
    "# your code here\n",
    "\n",
    "import os\n",
    "# 단계 1: 파일 경로 지정하기읽기 및 저장 : ques_filepath, ans_filepath\n",
    "ques_filepath = '[Dataset] cosmetics(ques)KO.txt'\n",
    "ans_filepath = '[Dataset] cosmetics(ans)KO.txt'\n",
    "\n",
    "# 질문 및 대답 파일 내용을 문자열로 읽어 소문자로 변경하여 저장하기 \n",
    "with open(ques_filepath, 'r', encoding='utf-8') as file:\n",
    "    raw_data_ques = file.read().lower()\n",
    "\n",
    "with open(ans_filepath, 'r', encoding='utf-8') as file:\n",
    "    raw_data_ans = file.read().lower()\n",
    "\n",
    "\n",
    "# 저장된 데이터의 길이 확인\n",
    "print(f'Length of raw_data_ques: {len(raw_data_ques)}')\n",
    "print(f'Length of raw_data_ans: {len(raw_data_ans)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t729o2v7aTGp"
   },
   "source": [
    "####  세분화, 표제어 추출,  단어 토큰화\n",
    "\n",
    "모듈 26 코사인 유사성 노트북에서 배운 방법을 참조하여 데이터를 세분화, 토큰화, 표제어 추출로 전처리 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 문장 세분화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1625201872991,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "bd6adnm0aTGp",
    "outputId": "3ebb414b-4af6-4b08-b180-c9a9a750ea0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in sent_tokens_ques: 10\n",
      "Number of sentences in sent_tokens_ans: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aruka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 1.2.3 문장 세분화 후 길이확인하기\n",
    "# question 과 answer 데이터에 대해 sent_tokenize() 사용하여 문서를 문장 목록으로 변환한다 \n",
    "# sent_tokens_ques / sent_tokens_ans  에 저장\n",
    "# your code here\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "sent_tokens_ques = nltk.sent_tokenize(raw_data_ques)\n",
    "sent_tokens_ans = nltk.sent_tokenize(raw_data_ans)\n",
    "\n",
    "\n",
    "# 토근화된 데이터 길이 확인하기 : sent_tokens_ans, sent_tokens_ques\n",
    "print(f'Number of sentences in sent_tokens_ques: {len(sent_tokens_ques)}')\n",
    "print(f'Number of sentences in sent_tokens_ans: {len(sent_tokens_ans)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1625201874211,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "h6JFAfDRaTGp",
    "outputId": "11eb25dd-d12b-4b5a-bf22-710a50655835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 저의 피부에 추천할 만한 제품을 알려주세요.\n",
      "A: 고객님의 피부 타입에 따라 추천할 수 있는 제품이 다릅니다.\n",
      "\n",
      "Q: 이 제품의 가격은 얼마인가요?\n",
      "A: 피부 타입(지성, 건성 등)과 주요 문제(여드름, 주름 등)를 알려주시면 맞춤형 제품을 추천해 드리겠습니다.\n",
      "\n",
      "Q: 이 제품의 주요 성분은 무엇인가요?\n",
      "A: 제품의 가격은 제품 종류와 브랜드에 따라 다릅니다.\n",
      "\n",
      "Q: 이 제품은 어떤 피부 타입에 적합한가요?\n",
      "A: 구체적인 제품명을 알려주시면 정확한 가격을 확인해 드리겠습니다.\n",
      "\n",
      "Q: 화장품을 사용하기 전에 무엇을 고려해야 하나요?\n",
      "A: 제품의 주요 성분은 제품의 포장지나 웹사이트에서 확인할 수 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 질문과 답변 매칭한 딕셔너리 - ques_ans_pairs 생성한 후 상위 5개 출력해 보기\n",
    "ques_ans_pairs = {sent_tokens_ques[i]: sent_tokens_ans[i] for i in range(min(len(sent_tokens_ques), len(sent_tokens_ans)))}\n",
    "\n",
    "# 상위 5개 출력\n",
    "for i, (ques, ans) in enumerate(ques_ans_pairs.items()):\n",
    "    if i < 5:\n",
    "        print(f'Q: {ques}')\n",
    "        print(f'A: {ans}\\n')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1625201875128,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "LYI2uuyTaTGq",
    "outputId": "a5594e85-0654-47e9-df50-b5f167eac199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokens in questions: ['저의', '피부에', '추천할', '만한', '제품을', '알려주세요', '.', '이', '제품의', '가격은', '얼마인가요', '?', '이', '제품의', '주요', '성분은', '무엇인가요', '?', '이', '제품은', '어떤', '피부', '타입에', '적합한가요', '?', '화장품을', '사용하기', '전에', '무엇을', '고려해야', '하나요', '?', '이', '제품의', '사용법을', '알려주세요', '.', '이', '제품에', '대한', '고객', '리뷰를', '어디서', '볼', '수', '있나요', '?', '제품에', '알레르기', '반응이']\n",
      "Word tokens in answers: ['고객님의', '피부', '타입에', '따라', '추천할', '수', '있는', '제품이', '다릅니다', '.', '피부', '타입', '(', '지성', ',', '건성', '등', ')', '과', '주요', '문제', '(', '여드름', ',', '주름', '등', ')', '를', '알려주시면', '맞춤형', '제품을', '추천해', '드리겠습니다', '.', '제품의', '가격은', '제품', '종류와', '브랜드에', '따라', '다릅니다', '.', '구체적인', '제품명을', '알려주시면', '정확한', '가격을', '확인해', '드리겠습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "# raw_data_ques와 raw_data_ans 단어 토큰화하고 출력하기 : word_tokens_ques 저장\n",
    "word_tokens_ques = nltk.word_tokenize(raw_data_ques)\n",
    "word_tokens_ans = nltk.word_tokenize(raw_data_ans)\n",
    "\n",
    "# 단어 토큰화된 결과 출력\n",
    "print(f'Word tokens in questions: {word_tokens_ques[:50]}')  # 상위 50개 단어 출력\n",
    "print(f'Word tokens in answers: {word_tokens_ans[:50]}')    # 상위 50개 단어 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5 표제어 추출\n",
    "WordNetleMmatizer를 사용하여 단어 토큰에서 표제어를 추출하는 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1625201875130,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "-7sg_IsiaTGq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized tokens in questions: ['저의', '피부에', '추천할', '만한', '제품을', '알려주세요', '.', '이', '제품의', '가격은', '얼마인가요', '?', '이', '제품의', '주요', '성분은', '무엇인가요', '?', '이', '제품은', '어떤', '피부', '타입에', '적합한가요', '?', '화장품을', '사용하기', '전에', '무엇을', '고려해야', '하나요', '?', '이', '제품의', '사용법을', '알려주세요', '.', '이', '제품에', '대한', '고객', '리뷰를', '어디서', '볼', '수', '있나요', '?', '제품에', '알레르기', '반응이']\n",
      "Lemmatized tokens in answers: ['고객님의', '피부', '타입에', '따라', '추천할', '수', '있는', '제품이', '다릅니다', '.', '피부', '타입', '(', '지성', ',', '건성', '등', ')', '과', '주요', '문제', '(', '여드름', ',', '주름', '등', ')', '를', '알려주시면', '맞춤형', '제품을', '추천해', '드리겠습니다', '.', '제품의', '가격은', '제품', '종류와', '브랜드에', '따라', '다릅니다', '.', '구체적인', '제품명을', '알려주시면', '정확한', '가격을', '확인해', '드리겠습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "# LemTokens() 정의하기\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# 표제어 추출 결과 출력\n",
    "lemmatized_tokens_ques = LemTokens(word_tokens_ques)\n",
    "lemmatized_tokens_ans = LemTokens(word_tokens_ans)\n",
    "\n",
    "print(f'Lemmatized tokens in questions: {lemmatized_tokens_ques[:50]}')  # 상위 50개 단어 출력\n",
    "print(f'Lemmatized tokens in answers: {lemmatized_tokens_ans[:50]}')    # 상위 50개 단어 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.6 정규화\n",
    "지식 기반에 유용하지 않은 구두점을 제거하는 함수를 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1625201875457,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "tNpTcnZQaTGq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized tokens in questions: [['저의', '피부에', '추천할', '만한', '제품을', '알려주세요'], ['이', '제품의', '가격은', '얼마인가요']]\n",
      "Normalized tokens in answers: [['고객님의', '피부', '타입에', '따라', '추천할', '수', '있는', '제품이', '다릅니다'], ['피부', '타입지성', '건성', '등과', '주요', '문제여드름', '주름', '등를', '알려주시면', '맞춤형', '제품을', '추천해', '드리겠습니다']]\n"
     ]
    }
   ],
   "source": [
    "# 1.2.6 정규화\n",
    "# 지식 기반에 유용하지 않은 구두점을 제거하는 함수 작성\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "# LemNormalize() 정의하기\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# 정규화 결과 출력\n",
    "normalized_tokens_ques = [LemNormalize(sentence) for sentence in sent_tokens_ques]\n",
    "normalized_tokens_ans = [LemNormalize(sentence) for sentence in sent_tokens_ans]\n",
    "\n",
    "print(f'Normalized tokens in questions: {normalized_tokens_ques[:2]}')  # 상위 2개 문장의 단어 출력\n",
    "print(f'Normalized tokens in answers: {normalized_tokens_ans[:2]}')    # 상위 2개 문장의 단어 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yBNkjCkaTGq"
   },
   "source": [
    "## 2. 챗봇 기능 추가 - 코사인 유사성\n",
    "데이터 세트를 문서 벡터로 변환 할 것입니다. 코사인 유사성은 유사한 벡터를 찾을 수 있게 해주며, 이러한 벡터는 의미가 비슷하다고 가정할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1625201875457,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "YKToF6tBaTGq"
   },
   "outputs": [],
   "source": [
    "# 2.1.1 입력 및 응답 목록 작성\n",
    "GREETING_INPUTS = [\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\", \"hey there\"]\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "# 인사말을 수신하고 반환하는 함수 만들기\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split(): # 문장의 각 단어를 살펴봅니다.\n",
    "        if word.lower() in GREETING_INPUTS: # 단어가 GREETING_INPUT와 일치하는지 확인합니다.\n",
    "            return random.choice(GREETING_RESPONSES) # Greeting_Response로 답장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2.1.2 끝인삿말 대응하기\n",
    "GOODBYE_INPUTS = [\"bye\", \"see you!\", \"unit\", \"exit\"]\n",
    "GOODBYE_RESPONSES = [\"Goodbye!\", \"See you later!\", \"Take care!\", \"Farewell!\"]\n",
    "\n",
    "# 끝인삿말을 수신하고 반환하는 함수 만들기\n",
    "def goodbye(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GOODBYE_INPUTS:\n",
    "            return random.choice(GOODBYE_RESPONSES)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG8J9Y4haTGq"
   },
   "source": [
    "챗봇의 기능은 챗봇을 실행하기 위한 루프를 만듦으로써 이루어집니다. 아래 기능을 살펴봅니다. 함수의 각 줄은 중요한 단계를 수행하기 위해 다른 함수를 호출하기 때문에 중요합니다. 'response' 함수는 챗봇이 어떻게 행동하는지에 대한 작동 방식을 담당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1625201875761,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "ljpdA9lXaTGq"
   },
   "outputs": [],
   "source": [
    "# 2.1.3 질문을 받고 답변을 반환하는 함수 만들기\n",
    "# your code here\n",
    "\n",
    "def response(user_response):\n",
    "    robo_response = ''\n",
    "    sent_tokens_ques.append(user_response)\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sent_tokens_ques)\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix)\n",
    "    sim_scores = cosine_similarities.flatten()\n",
    "    idx = sim_scores.argsort()[-2]\n",
    "    flat = sim_scores.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    \n",
    "    if req_tfidf == 0:\n",
    "        robo_response = \"I am sorry! I don't understand you.\"\n",
    "    else:\n",
    "        robo_response = sent_tokens_ans[idx]\n",
    "    \n",
    "    sent_tokens_ques.pop()\n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MObdf0DbaTGq"
   },
   "source": [
    "마지막으로 챗봇 인터페이스를 만들고 이를 중심으로 페르소나를 만들어 봅시다. 우리가 챗봇을 '제인'이라고 부르고 코사인 유사성을 사용하여 질문과 유사한 FAQ를 찾아 대답하도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10210,
     "status": "ok",
     "timestamp": 1625201887211,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "kAhwDtRAaTGr",
    "outputId": "a189d9b9-b5a9-472a-bcd2-0d1c3ec54cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: 안녕하세요.무엇을 도와드릴까요? (Type 'bye' to exit)\n",
      "You: 이 제품은 어떤 피부 타입에 적합한가요?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aruka\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\aruka\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: 구체적인 제품명을 알려주시면 정확한 가격을 확인해 드리겠습니다.\n",
      "You: 이 제품의 사용법을 알려주세요.\n",
      "Chatbot: 특정 제품에 대해 알고 싶으시면 제품명을 알려주세요.\n",
      "You: 제품에 알레르기 반응이 있는지 어떻게 확인하나요?\n",
      "Chatbot: 피부 타입에 따라 적합성을 확인하실 수 있습니다.\n",
      "You: bye\n",
      "Chatbot: Farewell!\n"
     ]
    }
   ],
   "source": [
    "# 2.1.4 챗봇 테스트\n",
    "# your code here\n",
    "\n",
    "# 챗봇 테스트\n",
    "print(\"Chatbot: 안녕하세요.무엇을 도와드릴까요? (Type 'bye' to exit)\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if goodbye(user_input) is not None:\n",
    "        print(\"Chatbot:\", goodbye(user_input))\n",
    "        break\n",
    "    elif greeting(user_input) is not None:\n",
    "        print(\"Chatbot:\", greeting(user_input))\n",
    "    else:\n",
    "        print(\"Chatbot:\", response(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti57IhXEaTGr"
   },
   "source": [
    "## 3. Doc2vec를 이용한 챗봇 기능\n",
    "\n",
    "챗봇을 만들기 위한 한 가지 유형의 모델을 더 다룰 것입니다. 코사인 유사성 모델 알고리즘은 두 문장 사이의 유사성을 찾는데 사용됩니다. 하지만 이제 신경망을 사용해서 이 문제를 해결해 보려합니다. 살펴보도록 하겠습니다.\n",
    "\n",
    "Doc2Vec은 기본적으로 문서에서 벡터를 생성하는 신경망 기반 모델입니다. Doc2vec을 이해하기 위해서는 word2vec도 이해해야 합니다.\n",
    "\n",
    "#### word2vec란?\n",
    "이는 삽입 단어를 생성하는 모델이며, 여기서는 텍스트의 큰 말뭉치를 입력으로 받고 일반적으로 수백 개 차원의 벡터 공간을 생성합니다. \n",
    "\n",
    "2013년 9월과 10월 사이에 구글의 연구팀에 의해 두 개의 논문에 소개되었습니다. Word2Vec의 기본 가정은 유사한 맥락을 공유하는 두 단어가 유사한 의미를 공유하며 결과적으로 모델에서 유사한 벡터 표현을 공유한다는 것입니다.\n",
    "\n",
    "예를 들어, \"은행\", \"화폐\", \"계좌\"는 \"달러\", \"대출\", \"신용\"과 같은 유사한 주변 단어와 함께 종종 사용되며, 따라서 Word2Vec에 따르면 이들은 유사한 벡터 표현을 공유합니다.\n",
    "\n",
    "![Image](img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajt10YajaTGr"
   },
   "source": [
    "#### doc2vec 란?\n",
    "\n",
    "doc2vec의 목적은 말뭉치의 모든 단어에 대한 특징 벡터를 계산하는 word2vec와 달리 문장/단락/문서의 수치 표현을 생성하는 것입니다. doc2vec은 말뭉치의 모든 문서에 대한 특징 벡터를 계산합니다. doc2vec에 의해 생성된 벡터는 문장/단락/문서 간의 유사성 찾기와 같은 작업에 사용될 수 있습니다.\n",
    "\n",
    "<strong> doc2vec의 속성을 사용하여 우리만의 유사성 모델을 만들 것입니다.</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rz_EMVtaTGr"
   },
   "source": [
    "관련 라이브러리를 가져오는 것으로 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10602,
     "status": "ok",
     "timestamp": 1625199335390,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "ItqcrhJpa8nd",
    "outputId": "2348a912-2fd5-4eda-fbf7-02dd45e96220"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subprocess와 sys 모듈을 사용하여 gensim 버전 3.8.1을 설치하는 부분입니다.\n",
    "import subprocess\n",
    "import sys\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gensim == 3.8.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가로 gensim upgrade 실행하기\n",
    "# !pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1625201893472,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "u0uEPI3haTGs"
   },
   "outputs": [],
   "source": [
    "# gensim의 Doc2Vec와 TaggedDocument 클래스를 가져오고,\n",
    "# nltk.tokenize에서 word_tokenize 함수를 가져옵니다.\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCN-DoefaTGs"
   },
   "source": [
    "첫 번째 주요 목표는 데이터에 태그를 지정하는 것입니다. doc2vec 모델은 데이터를 효과적으로 사용하기 위해 태그를 지정해야 합니다. 다음은 doc2vec에 대한 [시작 코드](https://www.kaggle.com/fmitchell259/creating-a-doc2vec-model) 좋은 학습 링크입니다. 다음 [링크](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e) 도 유용하게 사용할 수 있으며 읽을 것을 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1625201893805,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "kXe558qcaTGs"
   },
   "outputs": [],
   "source": [
    "# 문장들을 소문자로 변환하고 단어로 토큰화하여 TaggedDocument 형식으로 변환한 후, tagged_data 리스트에 저장합니다.\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(sent_tokens_ques)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1625201895886,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "dfTTPFpQaTGs"
   },
   "outputs": [],
   "source": [
    "# 최대 에포크 수를 100으로 설정합니다.\n",
    "# 벡터의 크기를 20으로 설정합니다.\n",
    "# 학습률을 0.025로 설정합니다.\n",
    "max_epochs = 100\n",
    "vec_size = 20 # 벡터가 더 크려면 이것을 증가시키세요. 이것은 더 많은 차이를 의미합니다. \n",
    "alpha = 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfhX6BQeaTGs"
   },
   "source": [
    "다음 단계는 모델을 훈련시키는 것입니다. 이전처럼 훈련 과정을 실행하기 위해 `model.train` 함수를 사용하게 될 것입니다. Doc2vec 모델을 훈련하는 방법에 대한 자세한 정보는 [문서](https://radimrehurek.com/gensim/models/doc2vec.html) 를 참조하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45968,
     "status": "ok",
     "timestamp": 1625201943421,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "h7ScV7f0aTGs",
    "outputId": "e226e5a2-e46b-4908-85e3-98defa6964a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec 모델을 생성하고, 필요한 매개변수를 설정합니다.\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm=1)\n",
    "\n",
    "# model에 대한 단어 사전을 tagged_data를 사용하여 빌드합니다.\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "# 주어진 최대 에포크 수에 대해 모델을 학습시킵니다.\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=1)\n",
    "    model.alpha -= 0.0002\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "# 학습된 모델을 \"d2v.model\"이라는 파일로 저장합니다. \n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8THTIyMhaTGs"
   },
   "source": [
    "### doc2vec 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1625201943421,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "rc2d1J9-aTGs"
   },
   "outputs": [],
   "source": [
    "# 저장된 모델을 로드합니다.\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec.load(\"d2v.model\")\n",
    "model.save(\"doc2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1625201943422,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "iH3JR16OaTGs"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터를 소문자로 변환하고 단어로 토큰화합니다.\n",
    "test_data = word_tokenize(\"How much is the price?\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImHFLBeFaTGs"
   },
   "source": [
    "`model.infer_vector` 함수를 사용하여 문서와 관련된 벡터를 추론할 수 있습니다. 그런 다음`most_similar` 함수를 사용하여 우리가 만든 벡터와 가장 유사한 벡터를 찾을 수 있습니다. 결과는 어떻습니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1625201943422,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "tHtGjgCtaTGt",
    "outputId": "c21a88e8-fdab-4470-dd7a-8ffc7ec69d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [ 0.01741733 -0.01209098  0.0146148   0.00122488 -0.01746475 -0.02229971\n",
      " -0.02078249 -0.01272703  0.0048309   0.01675028 -0.01677033 -0.01475264\n",
      " -0.00651561  0.02311771 -0.01931787  0.01501887  0.0157516   0.0176538\n",
      "  0.00582221 -0.00196055]\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용하여 문장의 벡터를 추론하고, v1에 저장한 후 출력합니다.\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1625201943423,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "6jcvVT6maTGt",
    "outputId": "8497571d-346f-42ae-f2d8-05c4f8b21cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('8', 0.17668059468269348), ('9', 0.13550099730491638), ('6', 0.09873324632644653), ('2', 0.05402598902583122)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aruka\\AppData\\Local\\Temp\\ipykernel_228\\3519407241.py:2: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  similar_doc = model.docvecs.most_similar(positive = [v1], topn = 4) #positive is an attribute that shows positive correlation first followed by the correlation value\n"
     ]
    }
   ],
   "source": [
    "# v1과 가장 유사한 문서 4개를 찾아 출력합니다.\n",
    "similar_doc = model.docvecs.most_similar(positive = [v1], topn = 4) #positive is an attribute that shows positive correlation first followed by the correlation value\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1625201943423,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "K5RVlbzkaTGt",
    "outputId": "3003c008-66f6-46d5-e1e8-3d1f1d283c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['화장품의', '유통', '기한은', '어떻게', '확인하나요', '?'], tags=['8'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 유사한 문서의 인덱스를 얻고, 해당 인덱스에 해당하는 문서를 출력합니다.\n",
    "num,_ = similar_doc[0]\n",
    "num = int(num)\n",
    "tagged_data[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nyV8stPaTGu"
   },
   "source": [
    "이전 코드 블록의 출력에서 이 모델이 생각했던 것 만큼 효과적이지 않다는 것이 분명합니다. 이 모델이 성공하기를 기대했지만 실패한 이유가 있습니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF3_3KTWaTGu"
   },
   "source": [
    "자세한 내용을 보려면 이 [링크](https://stackoverflow.com/questions/58206571/doc2vec-find-the-similar-sentence) 를 클릭하십시오. 이 문제의 요지는 다음과 같습니다.\n",
    "\n",
    "> Doc2Vec는 장난감 크기(toy-size)의 데이터셋에서 좋은 결과를 얻을 수 없으므로, 더 많은 데이터를 사용하기 전까지는 의미 있는 결과를 기대해서는 안 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkxnczmCaTGu"
   },
   "source": [
    "### 사전 학습된 doc2vec 사용\n",
    "\n",
    "따라서 인터넷에서 다운로드한 사전 검증된 모델을 사용하여 사용 사례를 최적화해 보겠습니다. The 우리가 취득 한 모델은 관련 언론 뉴스에 대한 훈련을 받았으며  [여기](https://github.com/jhlau/doc2vec) 서 다운로드 할 수 있습니다.\n",
    "\n",
    "모델을 로드하고 다시 평가해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 15060,
     "status": "ok",
     "timestamp": 1625202451516,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "OwYkOiukaTGu"
   },
   "outputs": [],
   "source": [
    "# 현재 작업 디렉토리에서 \"doc2vec.bin\" 파일을 로드합니다.\n",
    "model= Doc2Vec.load(os.getcwd()+r\"//doc2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625202451519,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "x3oHXA5zaTGu"
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터를 소문자로 변환하고 단어로 토큰화합니다.\n",
    "test_data = word_tokenize(\"How much is the price?\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625202451520,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "hkRhAtmEaTGu",
    "outputId": "7b5ccc32-2dab-470d-9ef6-ba2d7cd9820a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [ 0.01741733 -0.01209098  0.0146148   0.00122488 -0.01746475 -0.02229971\n",
      " -0.02078249 -0.01272703  0.0048309   0.01675028 -0.01677033 -0.01475264\n",
      " -0.00651561  0.02311771 -0.01931787  0.01501887  0.0157516   0.0176538\n",
      "  0.00582221 -0.00196055]\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용하여 문장의 벡터를 추론하고, v1에 저장한 후 출력합니다.\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1625202451520,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "wen70awiaTGu",
    "outputId": "1c791631-02ea-4f0f-cee0-08f627ab0cb3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저의 피부에 추천할 만한 제품을 알려주세요.\n",
      "[[-0.2525431]]\n",
      "이 제품의 가격은 얼마인가요?\n",
      "[[0.38808182]]\n",
      "이 제품의 주요 성분은 무엇인가요?\n",
      "[[0.04105826]]\n",
      "이 제품은 어떤 피부 타입에 적합한가요?\n",
      "[[-0.02006209]]\n",
      "화장품을 사용하기 전에 무엇을 고려해야 하나요?\n",
      "[[0.39660662]]\n",
      "이 제품의 사용법을 알려주세요.\n",
      "[[0.32489294]]\n",
      "이 제품에 대한 고객 리뷰를 어디서 볼 수 있나요?\n",
      "[[0.07771222]]\n",
      "제품에 알레르기 반응이 있는지 어떻게 확인하나요?\n",
      "[[0.19674292]]\n",
      "화장품의 유통 기한은 어떻게 확인하나요?\n",
      "[[0.14242297]]\n",
      "이 제품을 어디에서 구매할 수 있나요?\n",
      "[[-0.38730624]]\n"
     ]
    }
   ],
   "source": [
    "# sent_tokens에 있는 모든 문장에 대해 벡터를 추론하고, 각 문장과 v1 사이의 코사인 유사도를 출력합니다.\n",
    "for i in sent_tokens_ques:\n",
    "    v2 = model.infer_vector(word_tokenize(i.lower()))\n",
    "    print(i)\n",
    "    print(cosine_similarity(v1.reshape(1, -1),v2.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1625202451520,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "cGEBbf8eaTGu"
   },
   "outputs": [],
   "source": [
    "# 주어진 질문에 대한 답변을 계산하는 함수 calc_prob를 정의합니다.\n",
    "\n",
    "def calc_prob(v1, q):\n",
    "    probs = dict()\n",
    "    for i in q:\n",
    "        # 각 질문에 대해 벡터를 추론하고, v1과의 코사인 유사도를 계산합니다.\n",
    "        v2 = model.infer_vector(word_tokenize(i.lower()))\n",
    "        sim = cosine_similarity(v1.reshape(1, -1),v2.reshape(1, -1))\n",
    "        #print(i)\n",
    "        #print(sim)\n",
    "        probs[i] = sim[0][0]\n",
    "    \n",
    "    sorted_d = dict( sorted(probs.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    \n",
    "    # 유사도가 가장 높은 답변을 반환합니다.\n",
    "    return list(sorted_d.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1625202451520,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "NFb4-p0faTGu",
    "outputId": "0cd58c0a-2388-412a-c85c-a0b58d65ba1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('화장품을 사용하기 전에 무엇을 고려해야 하나요?', 0.39670742)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_prob(v1, sent_tokens_ques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISG0dPL8aTGv"
   },
   "source": [
    "이 모델이 더 효과적인 것처럼 보이기 때문에, 우리의 챗봇에 통합해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "executionInfo": {
     "elapsed": 12433,
     "status": "error",
     "timestamp": 1625202463943,
     "user": {
      "displayName": "Albert Anthony",
      "photoUrl": "",
      "userId": "06779463251817115427"
     },
     "user_tz": -420
    },
    "id": "S8JaMj8TaTGv",
    "outputId": "32ea27c9-eb69-4808-b6bc-fc6c6bbef947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제인: 제 이름은 제인입니다. 이 화장품에 대한 질문에 답변해 드리겠습니다. 나가려면 Bye를 입력하세요.\n",
      "이 제품을 어디에서 구매할 수 있나요?\n",
      "Jane: 이러한 정보를 바탕으로 적절한 제품을 선택하세요.\n",
      " (With similarity of  0.99997866 )\n",
      "저의 피부에 추천할 만한 제품을 알려주세요.\n",
      "Jane: 고객님의 피부 타입에 따라 추천할 수 있는 제품이 다릅니다.\n",
      " (With similarity of  0.99999785 )\n",
      "화장품을 사용하기 전에 무엇을 고려해야 하나요?\n",
      "Jane: 제품의 주요 성분은 제품의 포장지나 웹사이트에서 확인할 수 있습니다.\n",
      " (With similarity of  0.9998107 )\n",
      "bye\n",
      "제인: 안녕히 가세요.\n"
     ]
    }
   ],
   "source": [
    "# 사용자와 대화하는 부분입니다.\n",
    "\n",
    "flag=True\n",
    "print(\"제인: 제 이름은 제인입니다. 이 화장품에 대한 질문에 답변해 드리겠습니다. 나가려면 Bye를 입력하세요.\")\n",
    "\n",
    "while(flag==True):\n",
    "    # 사용자의 입력을 받고, 소문자로 변환합니다.\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    # 사용자가 'bye'를 입력하기 전까지 다음 동작을 반복합니다:\n",
    "    if(user_response!='bye'):\n",
    "        # 사용자가 'thanks' 또는 'thank you'를 입력하면 대화를 종료하고 \"You are welcome..\"을 출력합니다.\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"제인: You are welcome..\")\n",
    "        else:\n",
    "            # 사용자의 인사말에 대한 응답이 있는 경우 해당 응답을 출력합니다.\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"제인: \"+greeting(user_response))\n",
    "\n",
    "            # 그렇지 않은 경우, 주어진 질문에 대한 답변을 계산하고 출력합니다.\n",
    "            else:\n",
    "                print(\"제인: \",end=\"\")\n",
    "                resp= calc_prob(model.infer_vector(word_tokenize(user_response)), sent_tokens_ques)\n",
    "                print(ques_ans_pairs[resp[0]], )\n",
    "                print(' (With similarity of ',resp[1],')')\n",
    "\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"제인: 안녕히 가세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g55PaQhWputU"
   },
   "source": [
    "**두 모델의 성능** 을 관찰한 후 다음과 같은 몇 가지 명확한 결론을 내릴 수 있습니다:\n",
    "\n",
    "1. Doc2vec 모델은 단어 간의 관계를 이해하기 위해 더 많은 데이터가 필요합니다. 그리고 사전 훈련된 모델을 사용한 후에도 코사인 유사성 모델에 비해 모델의 응답의 품질이 아직 부족합니다.\n",
    "2. 코사인 유사성 모델은 더 작고 잘 정의된 데이터 세트에서 더 잘 작동합니다. 이는 몇 가지 간단한 질문을 효과적으로 해결할 수 있지만 컨텍스트를 필요로 하는 복잡한 질문은 해결할 수 없다는 의미입니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook_Module_27_Hotel_Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
